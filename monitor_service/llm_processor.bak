import google.generativeai as genai
import os
import json
import logging

logger = logging.getLogger(__name__)

# Configure Gemini API
genai.configure(api_key=os.getenv("GEMINI_API_KEY"))

# The precise prompt to get the Schema.org JSON
LLM_PROMPT_TEMPLATE = """
You are an expert recipe JSON generator.
I will provide you with **raw text extracted directly from a recipe**.
Your task is to accurately parse ONLY this provided text and generate a valid JSON-LD object for a Recipe following the Schema.org vocabulary.

**CRUCIAL GUIDELINES - STRICTLY ADHERE TO THESE:**
1.  **DO NOT HALLUCINATE OR INVENT ANY INFORMATION.** All recipe details (ingredients, instructions, times, yield, categories, cuisines, etc.) MUST come SOLELY from the provided "Recipe Text to Parse".
2.  If a piece of information (e.g., specific cookTime, recipeCategory, recipeCuisine, or an ingredient amount) is NOT clearly present in the provided text, either **omit that field entirely** from the JSON or provide a very generic placeholder like "Unknown" (prefer omission for missing details unless a field is mandatory for Schema.org and can be generically filled, like "1 serving" for servingSize if not found).
3.  The JSON MUST start with `{{\"@context\": \"https://schema.org/\", \"@type\": \"Recipe\", ...}}`.
4.  All recipe ingredients MUST be combined into a single `recipeIngredient` array, where each element is a string (e.g., "1 cup sugar", "2 large eggs"). Include measurements and descriptions exactly as found in the text.
5.  Each instruction step MUST be a separate object in the `recipeInstructions` array, with `@type: "HowToStep"` and `text: "Instruction text."`. **Carefully break down the recipe into distinct, logical, and concise steps, even if the original text combines multiple actions into one paragraph. Each step should represent one clear instruction or a small group of highly related actions.**
6.  Estimate `prepTime`, `cookTime`, and `totalTime` in ISO 8601 duration format (e.g., "PT30M" for 30 minutes, "PT1H15M" for 1 hour 15 minutes, "PT2H" for 2 hours, "PT7H" for 7 hours). Base estimations strictly on time indications within the text. If no explicit times, try to estimate roughly or omit.
7.  `recipeYield` should be a descriptive string like "4 servings" or "Makes about 1.5 litres", based *only* on the provided text.
8.  If 'author' is not specified in the text, use "Recipe Book".
9.  For 'image', use a descriptive text string like "close up view of [dish name] on a [color] platter", inferring [dish name] from the recipe title.
10. If there's a 'note' or general tips/context in the original text, include it in the 'note' field.
11. If nutrition information is missing, provide a generic `servingSize` like "1 serving".

**--- START OF RECIPE TEXT ---**
{recipe_text}
**--- END OF RECIPE TEXT ---**

**Output ONLY the JSON object. Do NOT include any other text, explanations, or markdown outside the JSON block.**
"""

def get_recipe_json(raw_text):
    """
    Sends raw recipe text to a Gemini LLM and returns Schema.org Recipe JSON.
    """
    if not os.getenv("GEMINI_API_KEY"):
        logger.error("GEMINI_API_KEY is not set in the .env file.")
        return None

    try:
        model = genai.GenerativeModel('gemini-1.5-flash-latest')
        prompt = LLM_PROMPT_TEMPLATE.format(recipe_text=raw_text)
        response = model.generate_content(prompt)

        if response and response.candidates:
            json_str = response.text.strip() # Corrected way to access text content
            # The LLM might sometimes wrap the JSON in markdown code blocks.
            # Attempt to strip it if present.
            if json_str.startswith("```json") and json_str.endswith("```"):
                json_str = json_str[7:-3].strip() # Remove ```json and ```

            try:
                # Validate JSON before returning
                recipe_json = json.loads(json_str)
                return recipe_json
            except json.JSONDecodeError as e:
                logger.error(f"LLM returned invalid JSON: {e}\nRaw LLM output: {json_str}")
                return None
        else:
            logger.warning(f"LLM response contained no text candidates for processing.")
            return None

    except Exception as e:
        logger.exception(f"Error calling LLM API: {e}")
        return None

# (Keep the list_available_models_diagnostic function if it's still in your file,
# but ensure it's not called by default in monitor.py's main execution block)
